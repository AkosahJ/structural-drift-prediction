{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgXyd5gEvBGI"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = list(uploaded.keys())[0]\n",
        "print(filename)"
      ],
      "metadata": {
        "id": "1eTmYP4VxEKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "xls = pd.ExcelFile(filename)\n",
        "print(xls.sheet_names)"
      ],
      "metadata": {
        "id": "xuNiGJxBv9wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "# Load the sheet\n",
        "df = pd.read_excel(filename, sheet_name=\"Jap-US\", header=[0,1, 2])\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Te1snWjewDjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show shape and a quick preview\n",
        "print(\"Shape:\", df.shape)\n",
        "display(df.head(2))"
      ],
      "metadata": {
        "id": "vd_3WjQD1vAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns.tolist()"
      ],
      "metadata": {
        "id": "1HLC5o43wZxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# FULL DICTIONARY OF COLUMN DEFINITIONS FOR THE NDE1.0 DATASET\n",
        "# ============================================================\n",
        "\n",
        "column_definitions = {\n",
        "\n",
        "    # --- Building Information ---\n",
        "    \"Building ID\": \"Unique identifier of the instrumented building.\",\n",
        "    \"B_Lat.\": \"Latitude of the building location (degrees).\",\n",
        "    \"B_Long.\": \"Longitude of the building location (degrees).\",\n",
        "    \"Soil info.\": \"Qualitative soil description (e.g., sandy clay, soft soil).\",\n",
        "    \"Vs30\": \"Average shear-wave velocity in the top 30 meters (m/s). Correct unit, file mistakenly shows m/s².\",\n",
        "    \"Height\": \"Total building height (cm → converted to meters).\",\n",
        "    \"No. of story\": \"Number of above-ground stories.\",\n",
        "    \"Typology\": \"Structural system type (e.g., RC, SRC, Steel).\",\n",
        "\n",
        "    # --- Earthquake/Event Information ---\n",
        "    \"Event Date\": \"Date and time of the recorded earthquake event.\",\n",
        "    \"E_Lat.\": \"Earthquake epicenter latitude (degrees).\",\n",
        "    \"E_Long.\": \"Earthquake epicenter longitude (degrees).\",\n",
        "    \"Magnitude\": \"Earthquake moment magnitude (Mw).\",\n",
        "    \"Epicentral distance (R)\": \"Distance from building to earthquake epicenter (km).\",\n",
        "\n",
        "    # --- Ordinate Intensity Measures ---\n",
        "    \"PGA\": \"Peak Ground Acceleration (cm/s² → converted to g).\",\n",
        "    \"PGV\": \"Peak Ground Velocity (cm/s → converted to m/s).\",\n",
        "    \"PGD\": \"Peak Ground Displacement (cm → meters).\",\n",
        "    \"AI\": \"Arias Intensity, an energy-based measure defined by ∫ a(t)^2 dt (cm/s).\",\n",
        "    \"DP\": \"Duration parameter (cm·s), related to cumulative shaking effects.\",\n",
        "    \"CAV\": \"Cumulative Absolute Velocity (∫ |a(t)| dt) measured in cm/s.\",\n",
        "\n",
        "    # --- Spectral Intensity Measures ---\n",
        "    \"SA1\": \"Spectral acceleration at first spectral period band (cm/s² → g).\",\n",
        "    \"SV1\": \"Spectral velocity at first period (cm/s).\",\n",
        "    \"SD1\": \"Spectral displacement at first period (cm).\",\n",
        "    \"SA2\": \"Spectral acceleration at second period band (cm/s² → g).\",\n",
        "    \"SV2\": \"Spectral velocity at second period (cm/s).\",\n",
        "    \"SD2\": \"Spectral displacement at second period (cm).\",\n",
        "\n",
        "    # --- Building Response (Output Quantities, Not Inputs) ---\n",
        "    \"Drift\": \"Maximum interstory drift ratio (dimensionless, cm/cm).\",\n",
        "    \"PTA\": \"Peak Top Acceleration measured at building top (cm/s²).\",\n",
        "    \"PTV\": \"Peak Top Velocity measured at building top (cm/s).\",\n",
        "    \"PTD\": \"Peak Top Displacement measured at building top (cm).\",\n",
        "\n",
        "    # --- Building Frequency ---\n",
        "    \"F1\": \"Fundamental (first-mode) frequency of the building (Hz).\",\n",
        "    \"F2\": \"Second-mode frequency of the building (Hz).\",\n",
        "\n",
        "    # --- Average Spectral Values ---\n",
        "    \"Avg_Sa\": \"Average spectral acceleration over specified period range (cm/s²).\",\n",
        "    \"Avg_Sv\": \"Average spectral velocity (cm/s).\",\n",
        "    \"Avg_Sd\": \"Average spectral displacement (cm).\",\n",
        "\n",
        "    # --- Duration of Strong Motion ---\n",
        "    \"Effective\": \"Effective duration of strong motion (seconds).\",\n",
        "    \"Bracketed 1 [0.05g]\": \"Bracketed duration between first and last exceedance of 0.05 g.\",\n",
        "    \"Uniform [0.05g]\": \"Continuous duration above 0.05 g.\",\n",
        "    \"Bracketed [0.1g]\": \"Bracketed duration above acceleration threshold 0.1 g.\",\n",
        "    \"Uniform [0.1g]\": \"Continuous duration above 0.1 g.\",\n",
        "    \"Bracketed [0.15g]\": \"Bracketed duration above 0.15 g.\",\n",
        "    \"Uniform [0.15g]\": \"Continuous duration above 0.15 g.\",\n",
        "    \"Bracketed [0.2g]\": \"Bracketed duration above 0.2 g.\",\n",
        "    \"Uniform [0.2g]\": \"Continuous duration above 0.2 g.\",\n",
        "    \"Significant_a1 [(5-75)%]\": \"Significant duration based on Arias Intensity (5–75%).\",\n",
        "    \"Significant_a2 [(5-95)%]\": \"Significant duration based on Arias Intensity (5–95%).\",\n",
        "    \"Significant_v1 [(5-75)%]\": \"Velocity-based significant duration (5–75%).\",\n",
        "    \"Significant_v2 [(5-95)%]\": \"Velocity-based significant duration (5–95%).\",\n",
        "    \"Significant_d1 [(5-75)%]\": \"Displacement-based significant duration (5–75%).\",\n",
        "    \"Significant_d2 [(5-95)%]\": \"Displacement-based significant duration (5–95%).\",\n",
        "    \"ZX\": \"Additional duration/intensity metric defined in the dataset documentation (seconds).\"\n",
        "}\n",
        "\n",
        "print(\"Loaded dictionary with\", len(column_definitions), \"column definitions.\")"
      ],
      "metadata": {
        "id": "knJtmB5TAnz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset with 3 header rows\n",
        "df_raw = pd.read_excel(filename, sheet_name=\"Jap-US\", header=[0,1,2])\n",
        "\n",
        "# Build clean single-level column names\n",
        "clean_names = []\n",
        "for c in df_raw.columns:\n",
        "    category, name, unit = c\n",
        "    clean = f\"{name}\".strip().replace(\" \", \"_\")\n",
        "    clean_names.append(clean)\n",
        "\n",
        "df = df_raw.copy()\n",
        "df.columns = clean_names\n",
        "\n",
        "# ---- SELECT RELEVANT COLUMNS ----\n",
        "keep = [\n",
        "    \"Vs30\",\n",
        "    \"Height\",\n",
        "    \"No._of_story\",\n",
        "    \"Typology\",\n",
        "    \"PGA\",\n",
        "    \"PGV\",\n",
        "    \"PGD\",\n",
        "    \"AI\",\n",
        "    \"SA1\",\n",
        "    \"SA2\",\n",
        "    \"Drift\",\n",
        "    \"PTA\",\n",
        "    \"PTV\",\n",
        "    \"PTD\",\n",
        "    \"F1\",\n",
        "    \"F2\",\n",
        "    \"Effective\",\n",
        "    \"Significant_a2_[(5-95)%]\"\n",
        "]\n",
        "\n",
        "df = df[keep]\n",
        "\n",
        "# ---- UNIT CONVERSIONS ----\n",
        "\n",
        "# Convert height (cm → m)\n",
        "df[\"Height\"] = df[\"Height\"] / 100.0\n",
        "\n",
        "# Vs30: fix units in file (reported as m/s^2, but intended to be m/s)\n",
        "# No conversion needed\n",
        "df[\"Vs30\"] = pd.to_numeric(df[\"Vs30\"], errors=\"coerce\")\n",
        "\n",
        "# Convert PGA, SA1, SA2, PTA (cm/s^2 → g)\n",
        "to_g = [\"PGA\", \"SA1\", \"SA2\", \"PTA\"]\n",
        "for col in to_g:\n",
        "    df[col] = df[col] / 981.0\n",
        "\n",
        "# Convert PGV, PTV (cm/s → m/s)\n",
        "for col in [\"PGV\", \"PTV\"]:\n",
        "    df[col] = df[col] / 100.0\n",
        "\n",
        "# Convert PGD, PTD (cm → m)\n",
        "for col in [\"PGD\", \"PTD\"]:\n",
        "    df[col] = df[col] / 100.0\n",
        "\n",
        "# Drift is already dimensionless; F1, F2 are Hz; durations already sec.\n",
        "\n",
        "# ---- CLEAN TYPLOGY ----\n",
        "df[\"Typology\"] = df[\"Typology\"].astype(\"category\")\n",
        "\n",
        "# ---- REMOVE ROWS WITH MISSING TARGET ----\n",
        "df = df.dropna(subset=[\"Drift\"])\n",
        "\n",
        "print(\"Final dataset shape:\", df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "0XE4TMQ15enk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "G6v62EJC6T5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create performance level from drift ratio\n",
        "def performance_level(drift):\n",
        "    if drift < 0.005:\n",
        "        return \"IO\"\n",
        "    elif drift < 0.02:\n",
        "        return \"LS\"\n",
        "    else:\n",
        "        return \"CP\"\n",
        "\n",
        "df[\"PerfLevel\"] = df[\"Drift\"].apply(performance_level)\n",
        "\n",
        "df[\"PerfLevel\"].value_counts()"
      ],
      "metadata": {
        "id": "RgYSzUeB6UzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset skewed towards one performance level\n",
        "# Classifiers dropped\n",
        "\n",
        "# Impute missing values (already done for classification, but repeat for safety)\n",
        "df[\"Vs30\"] = df[\"Vs30\"].fillna(df[\"Vs30\"].median())\n",
        "df[\"Effective\"] = df[\"Effective\"].fillna(df[\"Effective\"].median())\n",
        "df[\"F1\"] = df[\"F1\"].fillna(df[\"F1\"].median())\n",
        "\n",
        "# One-hot encode Typology, drop_first to avoid dummy trap\n",
        "df_reg = pd.get_dummies(df, columns=[\"Typology\"], drop_first=True)\n",
        "\n",
        "# Define features and target\n",
        "X = df_reg.drop(columns=[\"Drift\"])\n",
        "y = df_reg[\"Drift\"]"
      ],
      "metadata": {
        "id": "yEQpcXYJ8PZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "0_d44I608Vj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Clean X_train / X_test so they're fully numeric -----\n",
        "# If you still have PerfLevel or other string columns, drop them.\n",
        "cols_to_drop = [\"PerfLevel\", \"Building_ID\", \"Network\", \"Event_Date\", \"Event ID\"]\n",
        "for c in cols_to_drop:\n",
        "    if c in X_train.columns:\n",
        "        X_train = X_train.drop(columns=[c])\n",
        "        X_test  = X_test.drop(columns=[c])\n",
        "\n",
        "# If any non-numeric columns remain, drop or encode them:\n",
        "non_numeric = [c for c,d in X_train.dtypes.items() if d == \"object\"]\n",
        "print(\"Non-numeric columns still present (will be dropped):\", non_numeric)\n",
        "X_train = X_train.drop(columns=non_numeric)\n",
        "X_test  = X_test.drop(columns=non_numeric)\n",
        "\n",
        "#  Ensure index alignment after drops -----\n",
        "X_train, X_test = X_train.align(X_test, join='inner', axis=1)  # keep only common columns\n",
        "\n",
        "# Standardize features for Linear Regression (helps numerics) -----\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled  = scaler.transform(X_test)\n",
        "\n",
        "# Retrain models -----\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(X_train_scaled, y_train)\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)   # RF can take unscaled features; we use original X_train"
      ],
      "metadata": {
        "id": "n722pD9H8dYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate -----\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "def evaluate(model, name, Xeval, Yeval):\n",
        "    y_pred = model.predict(Xeval)\n",
        "    mae = mean_absolute_error(Yeval, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(Yeval, y_pred))\n",
        "    r2 = r2_score(Yeval, y_pred)\n",
        "    print(f\"\\n{name} Performance:\")\n",
        "    print(f\"MAE:  {mae:.6f}\")\n",
        "    print(f\"RMSE: {rmse:.6f}\")\n",
        "    print(f\"R²:   {r2:.6f}\")\n",
        "    return y_pred\n",
        "\n",
        "# Evaluate Linear Regression on scaled data\n",
        "y_pred_lin = evaluate(linreg, \"Linear Regression\", X_test_scaled, y_test)\n",
        "\n",
        "# Evaluate RF on original (unscaled) data\n",
        "y_pred_rf  = evaluate(rf, \"Random Forest\", X_test, y_test)"
      ],
      "metadata": {
        "id": "EvKMd5yK9_o7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "importances = rf.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.title(\"Feature Importance Ranking (Random Forest)\")\n",
        "plt.bar(range(len(importances)), importances[indices])\n",
        "plt.xticks(range(len(importances)), X.columns[indices], rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print top 10\n",
        "for i in indices[:10]:\n",
        "    print(f\"{X.columns[i]}: {importances[i]:.4f}\")"
      ],
      "metadata": {
        "id": "6PmjT3-e-sqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Outout variables dropped\n",
        "\n",
        "\n",
        "# Defensive re-build and train/eval block\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1) Recreate df_reg from df to ensure we start from the same known dataframe\n",
        "# (df is the cleaned dataframe you created earlier)\n",
        "df_reg = pd.get_dummies(df, columns=[\"Typology\"], drop_first=True)\n",
        "\n",
        "# 2) Define target and full candidate feature set, then remove response columns & metadata\n",
        "target = \"Drift\"\n",
        "\n",
        "# Columns that are responses that must NOT be used as predictors\n",
        "bad_cols = [target, \"PTA\", \"PTV\", \"PTD\", \"PerfLevel\", \"Building ID\", \"Network\", \"Event Date\", \"Event ID\"]\n",
        "# drop any that don't exist safely\n",
        "cols_to_drop = [c for c in bad_cols if c in df_reg.columns]\n",
        "\n",
        "X = df_reg.drop(columns=cols_to_drop, errors='ignore')\n",
        "y = df_reg[target].astype(float)\n",
        "\n",
        "# 3) Defensive check: list any non-numeric columns remaining\n",
        "non_numeric = X.select_dtypes(include=['object','category']).columns.tolist()\n",
        "print(\"Non-numeric columns found (should be none):\", non_numeric)\n",
        "\n",
        "# If any non-numeric remain, either encode or drop them; here we will one-hot encode object cols if present\n",
        "if len(non_numeric) > 0:\n",
        "    X = pd.get_dummies(X, columns=non_numeric, drop_first=True)\n",
        "    print(\"One-hot encoded the remaining non-numeric columns.\")\n",
        "\n",
        "# Final numeric check\n",
        "non_numeric_after = X.select_dtypes(include=['object','category']).columns.tolist()\n",
        "print(\"Non-numeric columns after encoding (should be empty):\", non_numeric_after)"
      ],
      "metadata": {
        "id": "e5gTp5vBAfBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Train/test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5) Scale numeric features for linear models\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled  = scaler.transform(X_test)\n",
        "\n",
        "# 6) Train Linear Regression and Random Forest\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(X_train_scaled, y_train)\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "qLVFw4vnAizt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7) Evaluate helper\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "def evaluate(model, name, Xeval, Yeval):\n",
        "    y_pred = model.predict(Xeval)\n",
        "    mae = mean_absolute_error(Yeval, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(Yeval, y_pred))\n",
        "    r2 = r2_score(Yeval, y_pred)\n",
        "    print(f\"\\n{name} Performance:\")\n",
        "    print(f\"MAE:  {mae:.6e}\")\n",
        "    print(f\"RMSE: {rmse:.6e}\")\n",
        "    print(f\"R²:   {r2:.6f}\")\n",
        "    return y_pred\n",
        "\n",
        "y_pred_lin = evaluate(linreg, \"Linear Regression\", X_test_scaled, y_test)\n",
        "y_pred_rf  = evaluate(rf, \"Random Forest\", X_test, y_test)"
      ],
      "metadata": {
        "id": "t-NzmkNVAne1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8) Feature importances from Random Forest (show top 15)\n",
        "import matplotlib.pyplot as plt\n",
        "importances = rf.feature_importances_\n",
        "feat_names = X.columns\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "topn = 15\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.title(\"Top feature importances (Random Forest)\")\n",
        "plt.barh(range(topn), importances[indices][:topn][::-1])\n",
        "plt.yticks(range(topn), feat_names[indices][:topn][::-1])\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"feature_importance.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTop features:\")\n",
        "for i in indices[:topn]:\n",
        "    print(f\"{feat_names[i]}: {importances[i]:.4f}\")"
      ],
      "metadata": {
        "id": "0AFW7G42_MKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "coef_table = pd.DataFrame({\n",
        "    \"Feature\": X_train.columns,\n",
        "    \"Coefficient\": linreg.coef_\n",
        "})\n",
        "coef_table\n"
      ],
      "metadata": {
        "id": "xrXP8DANv_5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "64xFZN5OxEIh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}